{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSu3U-SNu8v6",
        "outputId": "36cde625-f8f7-4037-b699-67a041775455"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub in /opt/miniconda3/lib/python3.13/site-packages (0.36.0)\n",
            "Requirement already satisfied: filelock in /opt/miniconda3/lib/python3.13/site-packages (from huggingface_hub) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/miniconda3/lib/python3.13/site-packages (from huggingface_hub) (2025.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /opt/miniconda3/lib/python3.13/site-packages (from huggingface_hub) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/lib/python3.13/site-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /opt/miniconda3/lib/python3.13/site-packages (from huggingface_hub) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /opt/miniconda3/lib/python3.13/site-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/lib/python3.13/site-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/miniconda3/lib/python3.13/site-packages (from huggingface_hub) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/miniconda3/lib/python3.13/site-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.13/site-packages (from requests->huggingface_hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.13/site-packages (from requests->huggingface_hub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.13/site-packages (from requests->huggingface_hub) (2025.11.12)\n",
            "Requirement already satisfied: opencv-python in /opt/miniconda3/lib/python3.13/site-packages (4.12.0.88)\n",
            "Requirement already satisfied: torch in /opt/miniconda3/lib/python3.13/site-packages (2.8.0)\n",
            "Requirement already satisfied: numpy in /opt/miniconda3/lib/python3.13/site-packages (2.2.6)\n",
            "Requirement already satisfied: torchvision in /opt/miniconda3/lib/python3.13/site-packages (0.23.0)\n",
            "Requirement already satisfied: tqdm in /opt/miniconda3/lib/python3.13/site-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /opt/miniconda3/lib/python3.13/site-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/miniconda3/lib/python3.13/site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: setuptools in /opt/miniconda3/lib/python3.13/site-packages (from torch) (78.1.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /opt/miniconda3/lib/python3.13/site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in /opt/miniconda3/lib/python3.13/site-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /opt/miniconda3/lib/python3.13/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /opt/miniconda3/lib/python3.13/site-packages (from torch) (2025.9.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/miniconda3/lib/python3.13/site-packages (from torchvision) (12.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/lib/python3.13/site-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "# ===== INSTALL DEPENDENCIES =====\n",
        "!pip install huggingface_hub\n",
        "!pip install boto3 -q\n",
        "!pip install opencv-python torch numpy torchvision tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3Lo27xcqrOMq"
      },
      "outputs": [],
      "source": [
        "# Import the required libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from huggingface_hub import hf_hub_download\n",
        "import boto3\n",
        "from botocore import UNSIGNED\n",
        "from botocore.config import Config\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMr99Yo7x8N1"
      },
      "source": [
        "# Please double, triple, quadruple check that the below code runs without errors before submitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YhoE1nF2Pee"
      },
      "source": [
        "## TODO 1 - Enter your HuggingFace username below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ENyfncieqs6i"
      },
      "outputs": [],
      "source": [
        "hf_username = \"EleftheriaK\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lC0jUquq_06"
      },
      "source": [
        "## TODO 2 - Define your model EXACTLY as you did in your training code (otherwise there will be errors, and, possibly, tears).\n",
        "\n",
        "Note below the classname is 'YourModelArchitecture'. That's because it literally needs to be YOUR MODEL ARCHITECTURE. This class definition is later referred to below in the 'load_model_from_hub' method. The architecture must match here, or it will not be able to instantiate the model weights correctly once it downloads them from HuggingFace. Pay very close attention to getting this right, please.\n",
        "\n",
        "Replace the below code, and replace the corresponding line in the 'load_model_from_hub' method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cm-y1pPnOGkK"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 1. MODEL DEFINITION (must match training)\n",
        "# =============================================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models.video import r2plus1d_18, R2Plus1D_18_Weights\n",
        "\n",
        "class YourModelArchitecture(nn.Module):\n",
        "    def __init__(self, num_classes=7):\n",
        "        super().__init__()\n",
        "        weights = R2Plus1D_18_Weights.DEFAULT\n",
        "        self.backbone = r2plus1d_18(weights=weights)\n",
        "        in_features = self.backbone.fc.in_features\n",
        "        self.backbone.fc = nn.Linear(in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #(B, C, T, H, W)\n",
        "        return self.backbone(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qahq0xG2rs4h"
      },
      "source": [
        "## Download the test data from s3, and create the corresponding dataset + dataloader.\n",
        "\n",
        "There's no TODO for you here. This text is just here to explain to you what this code does.\n",
        "\n",
        "In this instance, the test data IS the training data you were provided in the Model Training notebook. This is by design. You do not have access to the test data. This is a simple check to make sure the mechanics of this notebook work.\n",
        "\n",
        "You should achieve the same accuracy here in this notebook, as you did in your previous notebook (random seed notwithstanding)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XBukVn9qrnFZ"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# DOWNLOAD TEST DATA FROM S3\n",
        "# =============================================================================\n",
        "\n",
        "def download_test_data(bucket_name='training-and-validation-data',download_dir='./test-data'):\n",
        "    s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
        "\n",
        "    bucket_name = 'prism-mvta'\n",
        "    prefix = 'training-and-validation-data/'\n",
        "\n",
        "    os.makedirs(download_dir, exist_ok=True)\n",
        "\n",
        "    paginator = s3.get_paginator('list_objects_v2')\n",
        "    pages = paginator.paginate(Bucket=bucket_name, Prefix=prefix)\n",
        "\n",
        "    video_names = []\n",
        "\n",
        "    for page in pages:\n",
        "        if 'Contents' not in page:\n",
        "            print(\"No files found at the specified path!\")\n",
        "            break\n",
        "\n",
        "        print(\"Downloading test data:\\n\")\n",
        "        for obj in tqdm(page['Contents']):\n",
        "            key = obj['Key']\n",
        "            filename = os.path.basename(key)\n",
        "\n",
        "            if not filename:\n",
        "                continue\n",
        "\n",
        "            video_names.append(filename)\n",
        "            local_path = os.path.join(download_dir, filename)\n",
        "            # print(f\"Downloading: {filename}\")\n",
        "            s3.download_file(bucket_name, key, local_path)\n",
        "\n",
        "    print(f\"\\nDownloaded {len(video_names)} test videos\")\n",
        "    return download_dir\n",
        "\n",
        "\n",
        "# ============================================================================= # DATASET AND DATALOADER =============================================================================\n",
        "weights = R2Plus1D_18_Weights.DEFAULT\n",
        "preprocess = weights.transforms()\n",
        "\n",
        "class VideoDataset(Dataset):\n",
        "    \"\"\"Dataset for loading videos from a folder. Labels from filename prefix.\"\"\"\n",
        "\n",
        "    def __init__(self, video_dir, frame_size=(112, 112), target_frames=16, augment=None, do_preprocess=True):\n",
        "        self.video_dir = video_dir\n",
        "        self.frame_size = frame_size\n",
        "        self.target_frames = target_frames\n",
        "        self.augment = augment\n",
        "        self.do_preprocess = do_preprocess\n",
        "\n",
        "        self.video_files = [f for f in os.listdir(video_dir) if f.endswith(('.mp4', '.avi', '.mov'))]\n",
        "        self.labels = [int(f.split('_')[0]) - 1 for f in self.video_files] \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.video_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        video_path = os.path.join(self.video_dir, self.video_files[idx])\n",
        "        frames = self._load_video(video_path)\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.augment:\n",
        "            frames = self.augment(frames)\n",
        "        \n",
        "        if self.do_preprocess:\n",
        "           x = frames.permute(1,0,2,3)\n",
        "           x = preprocess(x)\n",
        "           frames = x.permute(1,0,2,3)\n",
        "\n",
        "        return frames, label\n",
        "\n",
        "    def _load_video(self, path, target_frames=16):\n",
        "        cap = cv2.VideoCapture(path)\n",
        "        all_frames = []\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            all_frames.append(frame)\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "        T = self.target_frames\n",
        "        H, W = self.frame_size\n",
        "\n",
        "        if len(all_frames) == 0:\n",
        "            return torch.zeros(3, T, H, W)\n",
        "\n",
        "        idxs = np.linspace(0, len(all_frames) - 1, T).astype(int)\n",
        "        sampled = [cv2.resize(all_frames[i], (W, H)) for i in idxs]\n",
        "\n",
        "        frames = torch.from_numpy(np.array(sampled)).permute(3, 0, 1, 2).float() / 255.0\n",
        "\n",
        "        return frames\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    frames_list, labels = zip(*batch)\n",
        "    frames = torch.stack(frames_list)\n",
        "    frames = frames.permute(0, 2, 1, 3, 4)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    return frames, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9PVSdWKsP94"
      },
      "source": [
        "## TODO 3 - Download your model from HuggingFace and instantiate it\n",
        "\n",
        "Replace line 8 of the below code. Line 8 is where you instantiate YOUR MODEL ARCHITECTURE (which you re-defined above) with the weights you download from HuggingFace. Make sure you get the class name, and the arguments to the __init__ method correct.\n",
        "\n",
        "\n",
        "This code just downloads the same model which you uploaded in the last notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "203abeec725944909cb8ec2b39f3e2af",
            "70a4207be31e43ad811c8abd3be7f9ad",
            "2a4dd8eb46d5479abdea9d214c6e541c",
            "1c3c510ca9a248a1b942e4b5e3767cf2",
            "6747f1470898402b81ef8c0a3eb94245",
            "cd65765c817a4a35b79cb0d58a4f3a86",
            "b431d05102dc4ea28feecc8c4dc13916",
            "c5777468dc0f413e9237218bf5dc9d21",
            "25baeea261454e7a819d848e8940f350",
            "db6d5a814c6c45ba86470919d259619d",
            "10234769f7ed4e73b3348a9bd5d9e2ed"
          ]
        },
        "id": "LWuMOqY_sOdg",
        "outputId": "f65c7fe1-4950-4229-a51d-87d4b9e43fce"
      },
      "outputs": [
        {
          "ename": "RepositoryNotFoundError",
          "evalue": "401 Client Error. (Request ID: Root=1-6953ea8a-258b97625d1c1b760f3c9fbd;3ec0563d-87cd-43d3-92a5-13ebe0d17a0b)\n\nRepository Not Found for url: https://huggingface.co/EleftheriaK/mv-final-assignment/resolve/main/model.pt.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication\nInvalid username or password.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/huggingface_hub/utils/_http.py:402\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
            "\u001b[31mHTTPError\u001b[39m: 401 Client Error: Unauthorized for url: https://huggingface.co/EleftheriaK/mv-final-assignment/resolve/main/model.pt",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mRepositoryNotFoundError\u001b[39m                   Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel loaded from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m model = \u001b[43mload_model_from_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mhf_username\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/mv-final-assignment\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mload_model_from_hub\u001b[39m\u001b[34m(repo_id, num_classes)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_model_from_hub\u001b[39m(repo_id, num_classes=\u001b[32m10\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     model_path = \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel.pt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     model = YourModelArchitecture(num_classes=num_classes)\n\u001b[32m      9\u001b[39m     model.load_state_dict(torch.load(model_path, map_location=\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m))\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/huggingface_hub/file_download.py:1007\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    987\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[32m    988\u001b[39m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[32m    989\u001b[39m         local_dir=local_dir,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1004\u001b[39m         local_files_only=local_files_only,\n\u001b[32m   1005\u001b[39m     )\n\u001b[32m   1006\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1007\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/huggingface_hub/file_download.py:1114\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1111\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m pointer_path\n\u001b[32m   1113\u001b[39m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1114\u001b[39m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1116\u001b[39m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n\u001b[32m   1117\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m etag \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33metag must have been retrieved from server\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/huggingface_hub/file_download.py:1655\u001b[39m, in \u001b[36m_raise_on_head_call_error\u001b[39m\u001b[34m(head_call_error, force_download, local_files_only)\u001b[39m\n\u001b[32m   1646\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[32m   1647\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot find the requested files in the disk cache and outgoing traffic has been disabled. To enable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1648\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m hf.co look-ups and downloads online, set \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlocal_files_only\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to False.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1649\u001b[39m     )\n\u001b[32m   1650\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1651\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error.response.status_code == \u001b[32m401\u001b[39m\n\u001b[32m   1652\u001b[39m ):\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1655\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[32m   1656\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1657\u001b[39m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n\u001b[32m   1658\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[32m   1659\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error happened while trying to locate the file on the Hub and we cannot find the requested files\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1660\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m in the local cache. Please check your connection and try again or make sure your Internet connection\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1661\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m is on.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1662\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhead_call_error\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/huggingface_hub/file_download.py:1543\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[39m\n\u001b[32m   1541\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1542\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1543\u001b[39m         metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1544\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\n\u001b[32m   1545\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1546\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[32m   1547\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m storage_folder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m relative_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1548\u001b[39m             \u001b[38;5;66;03m# Cache the non-existence of the file\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/huggingface_hub/file_download.py:1460\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[39m\n\u001b[32m   1457\u001b[39m hf_headers[\u001b[33m\"\u001b[39m\u001b[33mAccept-Encoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33midentity\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# prevent any compression => we want to know the real size of the file\u001b[39;00m\n\u001b[32m   1459\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1460\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1461\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1462\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1463\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1465\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1466\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1467\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1468\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1469\u001b[39m hf_raise_for_status(r)\n\u001b[32m   1471\u001b[39m \u001b[38;5;66;03m# Return\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/huggingface_hub/file_download.py:283\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;66;03m# Recursively follow relative redirects\u001b[39;00m\n\u001b[32m    282\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m     response = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    290\u001b[39m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[32m    291\u001b[39m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n\u001b[32m    292\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m300\u001b[39m <= response.status_code <= \u001b[32m399\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/huggingface_hub/file_download.py:307\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[32m    306\u001b[39m response = http_backoff(method=method, url=url, **params)\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/huggingface_hub/utils/_http.py:452\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m error_code == \u001b[33m\"\u001b[39m\u001b[33mRepoNotFound\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m    432\u001b[39m     response.status_code == \u001b[32m401\u001b[39m\n\u001b[32m    433\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m error_message != \u001b[33m\"\u001b[39m\u001b[33mInvalid credentials in Authorization header\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    441\u001b[39m     \u001b[38;5;66;03m# => for now, we process them as `RepoNotFound` anyway.\u001b[39;00m\n\u001b[32m    442\u001b[39m     \u001b[38;5;66;03m# See https://gist.github.com/Wauplin/46c27ad266b15998ce56a6603796f0b9\u001b[39;00m\n\u001b[32m    443\u001b[39m     message = (\n\u001b[32m    444\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Client Error.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    445\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    450\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m https://huggingface.co/docs/huggingface_hub/authentication\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    451\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RepositoryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m400\u001b[39m:\n\u001b[32m    455\u001b[39m     message = (\n\u001b[32m    456\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBad request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m endpoint:\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m endpoint_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBad request:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    457\u001b[39m     )\n",
            "\u001b[31mRepositoryNotFoundError\u001b[39m: 401 Client Error. (Request ID: Root=1-6953ea8a-258b97625d1c1b760f3c9fbd;3ec0563d-87cd-43d3-92a5-13ebe0d17a0b)\n\nRepository Not Found for url: https://huggingface.co/EleftheriaK/mv-final-assignment/resolve/main/model.pt.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication\nInvalid username or password."
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# DOWNLOAD MODEL FROM HUGGING FACE\n",
        "# =============================================================================\n",
        "\n",
        "def load_model_from_hub(repo_id, num_classes=7):\n",
        "    model_path = hf_hub_download(repo_id=repo_id, filename=\"model.pt\")\n",
        "\n",
        "    model = YourModelArchitecture(num_classes=num_classes)\n",
        "    model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
        "\n",
        "    print(f\"Model loaded from {repo_id}\")\n",
        "    return model\n",
        "\n",
        "model = load_model_from_hub(f\"{hf_username}/mv-final-assignment\",num_classes=7)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NycfLBRksum4"
      },
      "source": [
        "## TODO 4\n",
        "\n",
        "Make sure the below code correctly evaluates your model performance on the given data!\n",
        "\n",
        "This is your last chance to verify this before submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzgdieGiw4_k",
        "outputId": "f655601a-a58c-449f-c5d4-3a3de3473f58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Downloading test data:\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 77/77 [00:53<00:00,  1.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Downloaded 77 test videos\n",
            "\n",
            "Running inference on 77 test videos...\n",
            "\n",
            "\n",
            "✗  pred=3  true=4  |      2.9ms  |  4_kling_20251209_Text_to_Video_Generate_a_452_1.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_kling_20251206_Text_to_Video_Generate_a_71_2.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_sadlfkjasldkfjasleijlkjfd.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_kling_20251209_Text_to_Video_Generate_a_491_0.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_kling_20251209_Image_to_Video_Generate_a_635_0.mp4\n",
            "✗  pred=3  true=4  |      2.7ms  |  4_kling_20251209_Image_to_Video_Generate_a_635_1.mp4\n",
            "✗  pred=3  true=2  |      2.7ms  |  2_kling_20251205_Text_to_Video_On_a_sandy_4976_0.mp4\n",
            "✗  pred=3  true=4  |      2.7ms  |  4_20251209_Text_to_Video_Generate_a_561_0.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_dslkaldskjflakjs.mp4\n",
            "✗  pred=3  true=4  |      2.7ms  |  4_kling_20251206_Text_to_Video_Generate_a_28_0.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_sdlkjslndflkseijlkjef.mp4\n",
            "✗  pred=3  true=2  |      2.7ms  |  2_sdlkjsaelijfksdjf.mp4\n",
            "✗  pred=3  true=2  |      2.7ms  |  2_sdafkjaslkclaksdjkas.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_asldkfjalwieaskdfaskdf.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_dsjlaeijlksjdfie.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_kling_20251206_Text_to_Video_Generate_a_315_2.mp4\n",
            "✗  pred=3  true=4  |      2.7ms  |  4_kling_20251209_Text_to_Video_Generate_a_377_1.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_kling_20251205_Text_to_Video_On_a_playg_5028_0.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_dsksdfjbvsdkj.mp4\n",
            "✗  pred=3  true=4  |      2.7ms  |  4_pushup_1f2da596-7619-4d55-9376-069e15a42a1a_h264.mp4\n",
            "✗  pred=3  true=2  |      2.7ms  |  2_dkdjwkndkfw.mp4\n",
            "✗  pred=3  true=4  |      2.7ms  |  4_sadflkjasldkjfalseij.mp4\n",
            "✗  pred=3  true=2  |      2.7ms  |  2_sdkjdsflkjfwa.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_sdlkfjalkjejafe.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_kling_kdjflaskdjf.mp4\n",
            "✗  pred=3  true=7  |      2.7ms  |  7_sadkjfkljekj.mp4\n",
            "✗  pred=3  true=2  |      2.7ms  |  2_difficult_2.mp4\n",
            "✗  pred=3  true=4  |      2.7ms  |  4_kling_20251207_Text_to_Video_Generate_a_521_1.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_kling_20251209_Text_to_Video_Generate_a_403_1.mp4\n",
            "✗  pred=3  true=2  |      2.7ms  |  2_sdlfjlewlkjkj.mp4\n",
            "✗  pred=3  true=2  |      2.7ms  |  2_dkdmkejkeimdh.mp4\n",
            "✗  pred=3  true=1  |      2.7ms  |  1_dksksjfwijf.mp4\n",
            "✗  pred=3  true=4  |      2.7ms  |  4_aslkjasmcalkewjlkje.mp4\n",
            "✗  pred=3  true=2  |      2.7ms  |  2_sdjfhafsldkjhjk.mp4\n",
            "✗  pred=3  true=2  |      2.7ms  |  2_kling_20251206_Text_to_Video_Generate_a_71_1.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_sadlfkjawelnflksdjf.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_kling_20251206_Text_to_Video_Generate_a_712_3.mp4\n",
            "✗  pred=3  true=2  |      2.7ms  |  2_difficult_sdafkljsalkfj.mp4\n",
            "✗  pred=3  true=6  |      2.7ms  |  6_kling_20251209_Text_to_Video_Generate_a_218_1.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_sadklfjasbnlkjlfkj.mp4\n",
            "✗  pred=3  true=4  |      2.7ms  |  4_kling_20251209_Text_to_Video_Generate_a_452_0.mp4\n",
            "✗  pred=3  true=6  |      2.7ms  |  6_dfjewaijsldkjfsaef.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_kling_20251206_Text_to_Video_Generate_a_17_0.mp4\n",
            "✗  pred=3  true=2  |      2.7ms  |  2_sadfasjldkfjaseifj.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_kling_20251209_Image_to_Video_Generate_a_613_1.mp4\n",
            "✗  pred=3  true=2  |      2.7ms  |  2_sdfkjsaleijflaskdjf.mp4\n",
            "✗  pred=3  true=4  |      2.7ms  |  4_dssalsdkfjweijf.mp4\n",
            "✗  pred=3  true=2  |      2.7ms  |  2_dfsaeklnvvalkej.mp4\n",
            "✗  pred=3  true=4  |      2.7ms  |  4_kling_20251206_Text_to_Video_Generate_a_315_3.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_kling_dskfseu.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_dkk873lkjlksajdf.mp4\n",
            "✗  pred=3  true=4  |      2.7ms  |  4_kling_20251209_Text_to_Video_Generate_a_561_1.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_sdflkjliejkjdf.mp4\n",
            "✗  pred=3  true=4  |      2.7ms  |  4_kling_20251209_Text_to_Video_Generate_a_218_0.mp4\n",
            "✗  pred=3  true=4  |      2.7ms  |  4_kling_20251206_Text_to_Video_Generate_a_58_0.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_kling_20251206_Text_to_Video_Generate_a_71_3.mp4\n",
            "✗  pred=3  true=5  |      2.7ms  |  5_sdfkljweoijlkjdsflkjweaij.mp4\n",
            "✗  pred=3  true=4  |      2.7ms  |  4_asdlkfjalsflnekj.mp4\n",
            "✗  pred=3  true=2  |      2.7ms  |  2_dsalkfjalwkenlke.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_sdlkfjaleknaksej.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_kling_20251209_Text_to_Video_Generate_a_190_1.mp4\n",
            "✗  pred=3  true=5  |      2.7ms  |  5_sadfjhaslfkjasdlkfjsa.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_kling_20251205_Text_to_Video_On_a_playg_5064_0.mp4\n",
            "✗  pred=3  true=4  |      2.7ms  |  4_sadlfkjlknewkjejk.mp4\n",
            "✗  pred=3  true=4  |      2.8ms  |  4_kling_20251209_Text_to_Video_Generate_a_588_2.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_sdfjwaiejflkasjdf.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_ewdfkjwaeoihjlkasdjf.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_kling_20251206_Text_to_Video_Generate_a_71_0.mp4\n",
            "✗  pred=3  true=2  |      2.7ms  |  2_dkjd823kjf.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_kling_20251209_Text_to_Video_Generate_a_491_2.mp4\n",
            "✗  pred=3  true=4  |      2.7ms  |  4_kling_20251209_Text_to_Video_Generate_a_190_0.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_kling_20251206_Text_to_Video_Generate_a_315_0.mp4\n",
            "✗  pred=3  true=4  |      2.7ms  |  4_kling_20251209_Text_to_Video_Generate_a_263_1.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_kling_20251205_Text_to_Video_In_a_grass_4697_0.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_sdlkjfaslkjfalskjdf.mp4\n",
            "✓  pred=3  true=3  |      2.7ms  |  3_kling_20251209_Text_to_Video_Generate_a_491_1.mp4\n",
            "✗  pred=3  true=4  |      2.7ms  |  4_aslkcasckmwlejk.mp4\n",
            "\n",
            "==================================================\n",
            "SUMMARY\n",
            "==================================================\n",
            "Total videos:         77\n",
            "Correct:              34\n",
            "Wrong:                43\n",
            "\n",
            "ACCURACY:             44.16%\n",
            "\n",
            "Total time:           77.86s\n",
            "Avg per video:        2.7ms\n",
            "Min latency:          2.7ms\n",
            "Max latency:          2.9ms\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "def evaluate(model, test_loader, dataset, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_times = []\n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (frames, labels) in enumerate(test_loader):\n",
        "            frames, labels = frames.to(device), labels.to(device)\n",
        "\n",
        "            # Time the forward pass\n",
        "            start_time = time.time()\n",
        "            outputs = model(frames)\n",
        "            if device.type == 'cuda':\n",
        "                torch.cuda.synchronize()  # wait for GPU to finish\n",
        "            end_time = time.time()\n",
        "\n",
        "            inference_time = (end_time - start_time) * 1000  # ms\n",
        "            all_times.append(inference_time)\n",
        "\n",
        "            preds = outputs.argmax(dim=1)\n",
        "\n",
        "            for i in range(labels.size(0)):\n",
        "                batch_idx = idx * test_loader.batch_size + i\n",
        "                video_name = dataset.video_files[batch_idx]\n",
        "                pred = preds[i].item()\n",
        "                true_label = labels[i].item()\n",
        "                is_correct = \"✓\" if pred == true_label else \"✗\"\n",
        "\n",
        "                print(f\"{is_correct}  pred={pred}  true={true_label}  |  {inference_time:>7.1f}ms  |  {video_name}\")\n",
        "\n",
        "            correct += preds.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy, all_preds, all_labels, all_times\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# RUN INFERENCE\n",
        "# =============================================================================\n",
        "\n",
        "def run_inference(model, bucket_name='training-and-validation-data'):\n",
        "    device = torch.device(\n",
        "    \"mps\" if torch.backends.mps.is_available()\n",
        "    else \"cuda\" if torch.cuda.is_available()\n",
        "    else \"cpu\")\n",
        "    \n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    # Download test data\n",
        "    test_dir = download_test_data(bucket_name, './test-data')\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Create dataloader\n",
        "    test_dataset = VideoDataset(test_dir, frame_size=(224, 224))\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=1,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        collate_fn=collate_fn\n",
        "    )\n",
        "\n",
        "    print(f\"\\nRunning inference on {len(test_dataset)} test videos...\")\n",
        "\n",
        "    # Warmup (optional, helps get consistent GPU timings)\n",
        "    if device.type == 'cuda':\n",
        "        dummy = torch.randn(1, 3, 1000, 224, 224).to(device)\n",
        "        with torch.no_grad():\n",
        "            _ = model(dummy)\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "    total_start = time.time()\n",
        "    accuracy, preds, labels, times = evaluate(model, test_loader, test_dataset, device)\n",
        "    total_end = time.time()\n",
        "\n",
        "    # Summary\n",
        "    num_correct = sum(p == l for p, l in zip(preds, labels))\n",
        "    num_wrong = len(preds) - num_correct\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"SUMMARY\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Total videos:         {len(preds)}\")\n",
        "    print(f\"Correct:              {num_correct}\")\n",
        "    print(f\"Incorrect:                {num_wrong}\")\n",
        "    print(f\"\")\n",
        "    print(f\"ACCURACY:             {accuracy*100:.2f}%\")\n",
        "    print(f\"\")\n",
        "    print(f\"Total time:           {total_end - total_start:.2f}s\")\n",
        "    print(f\"Avg per video:        {sum(times) / len(times):.1f}ms\")\n",
        "    print(f\"Min latency:          {min(times):.1f}ms\")\n",
        "    print(f\"Max latency:          {max(times):.1f}ms\")\n",
        "    print(\"=\"*50)\n",
        "    return accuracy, preds, labels\n",
        "\n",
        "_, _, _ = run_inference(model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "10234769f7ed4e73b3348a9bd5d9e2ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c3c510ca9a248a1b942e4b5e3767cf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db6d5a814c6c45ba86470919d259619d",
            "placeholder": "​",
            "style": "IPY_MODEL_10234769f7ed4e73b3348a9bd5d9e2ed",
            "value": " 611k/611k [00:01&lt;00:00, 592kB/s]"
          }
        },
        "203abeec725944909cb8ec2b39f3e2af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70a4207be31e43ad811c8abd3be7f9ad",
              "IPY_MODEL_2a4dd8eb46d5479abdea9d214c6e541c",
              "IPY_MODEL_1c3c510ca9a248a1b942e4b5e3767cf2"
            ],
            "layout": "IPY_MODEL_6747f1470898402b81ef8c0a3eb94245"
          }
        },
        "25baeea261454e7a819d848e8940f350": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a4dd8eb46d5479abdea9d214c6e541c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5777468dc0f413e9237218bf5dc9d21",
            "max": 611445,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25baeea261454e7a819d848e8940f350",
            "value": 611445
          }
        },
        "6747f1470898402b81ef8c0a3eb94245": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70a4207be31e43ad811c8abd3be7f9ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd65765c817a4a35b79cb0d58a4f3a86",
            "placeholder": "​",
            "style": "IPY_MODEL_b431d05102dc4ea28feecc8c4dc13916",
            "value": "model.pt: 100%"
          }
        },
        "b431d05102dc4ea28feecc8c4dc13916": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5777468dc0f413e9237218bf5dc9d21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd65765c817a4a35b79cb0d58a4f3a86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db6d5a814c6c45ba86470919d259619d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
